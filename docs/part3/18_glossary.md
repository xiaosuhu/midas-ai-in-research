# AI Literacy Glossary

## Foundational Terms

**Artificial Intelligence (AI)**  
A broad field focused on creating systems that can perform tasks that usually require human intelligence, such as reasoning, learning, pattern recognition, and decision-making.

**Machine Learning (ML)**  
A subset of AI where systems learn patterns from data rather than following explicit rules. Models improve performance by adjusting parameters based on examples.

**Deep Learning (DL)**  
A branch of machine learning that uses multilayer neural networks to learn complex patterns from images, text, audio, and other data types.

**Generative AI (GenAI)**  
Models that can create new content—text, images, audio, video, or code—based on patterns learned from large datasets.

---

## High-Level Application Areas

**Natural Language Processing (NLP)**  
Methods that allow machines to understand and generate human language. Common tasks include summarization, translation, question answering, and sentiment analysis.

**Computer Vision (CV)**  
Methods that enable machines to interpret visual data. Common tasks include image classification, object detection, segmentation, and image generation.

**Multimodal AI**  
Models that combine more than one data type (e.g., text + images, text + audio). These models support tasks such as visual question answering and image–text retrieval.

**Reinforcement Learning (RL)**  
Algorithms that learn through interaction with an environment, guided by rewards and penalties. Used in robotics, game-playing, and sequential decision systems.

---

## Core Concepts and Techniques

**Neural Networks**  
Computational structures composed of interconnected layers of units (“neurons”). These form the basis of most modern deep learning models.

**Training Data**  
The example data used to teach a model. Model performance depends heavily on the quality, quantity, and diversity of this data.

**Fine-Tuning**  
Adapting a pre-trained model to a specific dataset or task, enabling customization without training from scratch.

**Embeddings**  
Numeric vector representations of text, images, or other data that capture their semantic meaning.

**Inference**  
The process of using a trained model to generate outputs or predictions on new data.

---

## Common GenAI Model Types

**Large Language Models (LLMs)**  
Models trained to understand and generate natural language.  
Examples: GPT-4, GPT-5, Llama 3, Claude, Mistral.

**Vision Models**  
Models trained to understand visual data.  
Examples: ResNet, Vision Transformer (ViT), DINOv2, SAM, YOLO.

**Image Generation Models**  
Models that create realistic or stylized images.  
Examples: Stable Diffusion, Midjourney, DALL·E.

**Speech and Audio Models**  
Models for transcription, audio generation, and sound classification.  
Examples: Whisper, AudioLM, Vocos.

**Multimodal Models**  
Models combining text, images, audio, and/or video.  
Examples: GPT-4o, Gemini, Qwen-VL, LLaVA.

---

## Techniques and Terms Useful for Faculty

**Prompting**  
Crafting instructions that guide model behavior. Includes simple prompts, structured prompts, system messages, and chain-of-thought prompts.

**Retrieval-Augmented Generation (RAG)**  
A technique where an LLM retrieves relevant documents before generating a response, improving accuracy and reducing hallucinations.

**Transformers**  
The neural network architecture behind most state-of-the-art NLP and vision models. Uses attention mechanisms to identify which input elements are most relevant.

**Token**  
A small unit of text processed by LLMs (fragment of a word or punctuation). Cost and speed scale with token count.

**Hallucination**  
When a model produces confident but incorrect or fabricated information.

**Model Cards**  
Documentation describing a model’s training data, capabilities, intended use, limitations, and ethical considerations.
