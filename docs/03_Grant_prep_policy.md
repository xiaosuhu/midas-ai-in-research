# Grant Preparation and Policy

## 1. Introduction

The rise of generative artificial intelligence (GenAI) tools — large-language models, automated summarizers, AI-driven Gantt-chart or timeline generators, etc. — promises to transform how researchers develop grant proposals. By accelerating tasks like literature scoping, drafting narrative sections, or formatting budgets, AI can yield greater efficiency, consistency, and creative ideation. Particularly in competitive funding environments, the ability to rapidly iterate on proposals can help teams explore multiple aims, refine hypotheses, or re-package ideas for different funders.

At the same time, AI’s use raises institutional concerns, especially around originality (intellectual ownership), data confidentiality and management (especially when using public AI tools), and compliance with funder and university policy. It is therefore critical to treat AI as an *assistive tool* — not a substitute for researchers’ own intellectual contributions — and to embed ethical and compliance practices in AI-augmented grant development workflows.

## 2. AI for Grant Ideation and Planning

AI tools offer immediate value in the early, planning stages of grant development:

- **Literature Scoping and Gap Identification**  
  GenAI tools can help scan large literatures, summarize key findings, highlight trends, or suggest underexplored areas. This can help PIs and teams quickly map the landscape, identify gaps, and formulate promising research questions.

- **Drafting Specific Aims or Project Summaries**  
  Early-stage prompts (e.g., “Write a draft of specific aims for a project investigating X”) can yield coherent, structured drafts that teams can then refine. This accelerates brainstorming and supports less experienced writers.

- **Generating Timelines, Budgets, or Gantt Charts**  
  AI-driven project-management tools can assist in constructing realistic project timelines, milestone charts, resource allocations, and preliminary budgets.

When used responsibly — with human oversight, critical evaluation, and iteration — these capabilities expand the creative and organizational potential of research teams.

## 3. AI in Proposal Writing

Once a project plan and aims are outlined, GenAI can support the writing and formatting of the proposal:

- **Structuring Narrative Sections (Significance, Innovation, Approach)**  
  AI can help align sections with funder expectations and ensure logical flow.

- **Improving Readability and Alignment with Review Criteria**  
  AI can support clarity, coherence, and persuasive framing while helping writers meet page limits or structural requirements.

- **Language Polishing for Clarity and Impact**  
  AI assists with grammar, readability, conciseness, and tone.

However, AI-assisted writing must be carefully reviewed for scientific accuracy, proper citations, methodological clarity, and idea integrity. Ultimately, the human researcher must determine the final content, since much of the deeper logic of grantwriting — the tacit assumptions, strategic framing, and experiential knowledge that never appears explicitly on paper — can only be provided by experienced investigators and cannot be reliably inferred by AI.

## 4. Ethical and Policy Considerations

The use of GenAI in grant writing raises a suite of ethical, integrity, and policy issues. Recent analyses highlight risks including hallucinations, incorrect content, bias, potential IP violations, privacy breaches, and lack of reproducibility {cite}`Bjelobaba_2024_GenAI_integrity`.

Key guidelines for responsible AI use include:

- **Transparency and Documentation**  
  Researchers should document when and how AI tools are used (e.g., prompts and revisions).  
  See: *AI Usage Cards* framework {cite}`Wahle_2023_AI_Usage_Cards`.

- **Human Oversight**  
  Researchers are fully accountable for final content accuracy {cite}`Lin_2025_Beyond_principlism`.

- **Respect for Confidentiality, Privacy, and IP**  
  Avoid uploading sensitive or unpublished data to public AI tools.  
  See: U-M OVPR AI Guidelines (2025). {cite}`UM_OVPR_AI_guidelines_2025`

- **Critical Evaluation of AI Outputs**  
  AI can hallucinate citations, invent facts, or misrepresent studies — requiring careful validation.

Ethical AI use in grant writing means using AI to **support thinking** (organization, clarity, framing), not to replace original intellectual work.

## 5. UM and Sponsor Policies

### 5.1 University of Michigan Policies

U-M has established guidelines emphasizing privacy, security, and responsible AI use.

Key points:

- U-M provides secure internal AI tools to avoid risks associated with commercial platforms.{cite}`UM_GenAI_resources`

- Researchers **must not upload sensitive or unpublished data** into public AI tools.  
  Reference: U-M Ross IT AI Guidelines.

- OVPR (2025) discourages AI use in internal peer review due to confidentiality and bias risks.

- Students and researchers should **document** AI-generated or AI-assisted content in academic contexts.

For grant writing, this means using **internal tools**, avoiding exposure of sensitive material, and documenting AI involvement.

### 5.2 Funder Policies: NIH, NSF, and Others

#### NIH

- **Notice NOT-OD-25-132 (2025)**: Applications “substantially developed by AI” may be considered non-original and may be rejected. {cite}`NIH_NOT_OD_25_132`  
- Limits PIs to **six** applications per year starting Sept 25, 2025.  
- **Generative AI is prohibited in peer review** {cite}`NIH_NOT_OD_23_149`.  
- Applicants are responsible for ensuring accuracy, originality, and integrity of all text.

NIH does not forbid limited AI-assisted drafting, but the **intellectual substance must originate from humans**.

#### NSF

- NSF’s 2023 community notice permits proposers to use GenAI but emphasizes:  
  - Proposers are fully responsible for accuracy and authenticity.  
  - Confidential proposal content **cannot** be uploaded to commercial AI tools.  
  - Reviewers cannot use GenAI for proposal evaluation.  
  - Fabrication, falsification, or plagiarism remains misconduct under PAPPG.

#### Other Agencies (DOE, DOD, NASA, NOAA)

Current public policy is sparse. No widely publicized agency-wide rules comparable to NIH/NSF exist (as of 2025).  
Research shows that federal NOFOs rarely mention explicit AI-use criteria, indicating a **policy gap**.  
{cite}`Bateyko_2025_AI_governance_grants`

Until further clarification:

- Follow institutional policies (e.g., U-M guidelines).  
- Apply general research integrity principles (transparency, originality, confidentiality).

## 6. Case Example

### Mock NIH Summary Paragraph (Before vs. After AI Polishing)

**Before (human draft):**

> We plan to investigate how pollutant X affects gene expression in cell type Y under hypoxic conditions. This will help understand disease Z and could lead to potential therapeutic targets. We will use RNA-seq and functional assays...

**After (AI-polished):**

> This project aims to elucidate the molecular mechanisms by which pollutant X modulates gene regulatory networks in Y cells under hypoxia — bridging a critical gap in our understanding of pollutant-induced pathogenesis in Z. By combining high-throughput transcriptomics (Aim 1), targeted functional assays (Aim 2), and reversibility studies (Aim 3), we expect to identify novel regulatory nodes...

**Benefits:**  
Clearer structure, improved flow, stronger alignment with NIH expectations.

**Risks:**  
AI may overstate impact, introduce ambiguous claims, or add unsupported statements — requiring human correction.

AI works best as a **language refinement tool** when humans fully control scientific content.

## 7. Conclusion

Generative AI offers powerful tools that can greatly enhance efficiency, clarity, and creativity in grant proposal development. When used judiciously — with human oversight, transparency, and adherence to institutional and funder policies — AI can accelerate idea development and improve writing quality.

However, risks include loss of originality, confidentiality breaches, hallucinations, and noncompliance with evolving policies. NIH and NSF policies already place clear boundaries on acceptable use, and universities like U-M emphasize secure, documented, human-centered workflows.

AI should be treated as a **thought partner**, not a replacement for human expertise. Responsible integration ensures AI enhances scholarly work without compromising research integrity.

---
## References

```{bibliography}
:filter: docname in docnames
```
